{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "bzosmCAG7vEy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('tweet_emotions.csv')"
      ],
      "metadata": {
        "id": "0aFPV1V18E9X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "___p8-i68I7M",
        "outputId": "ba1ad458-414a-4b1c-e54a-27b85cd0c456"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     tweet_id   sentiment                                            content\n",
            "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
            "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
            "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
            "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
            "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip().lower()\n",
        "\n",
        "df['clean_content'] = df['content'].apply(clean_text)\n",
        "\n",
        "print(\"Sample cleaned content:\")\n",
        "for i in range(5):\n",
        "    print(f\"Original: {df['content'][i]}\")\n",
        "    print(f\"Cleaned: {df['clean_content'][i]}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRGdmfBQ71ve",
        "outputId": "645a1c60-ccfd-40a7-d525-90193a0237a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample cleaned content:\n",
            "Original: @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[\n",
            "Cleaned: tiffanylue i know i was listenin to bad habit earlier and i started freakin at his part\n",
            "\n",
            "Original: Layin n bed with a headache  ughhhh...waitin on your call...\n",
            "Cleaned: layin n bed with a headache ughhhhwaitin on your call\n",
            "\n",
            "Original: Funeral ceremony...gloomy friday...\n",
            "Cleaned: funeral ceremonygloomy friday\n",
            "\n",
            "Original: wants to hang out with friends SOON!\n",
            "Cleaned: wants to hang out with friends soon\n",
            "\n",
            "Original: @dannycastillo We want to trade with someone who has Houston tickets, but no one will.\n",
            "Cleaned: dannycastillo we want to trade with someone who has houston tickets but no one will\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values:\")\n",
        "print(missing_values)\n",
        "\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "print(\"\\nDataset shape after dropping missing values:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hiedSJe8OIk",
        "outputId": "65b741dc-679d-4f52-a00b-f057d7e17f18"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            "tweet_id         0\n",
            "sentiment        0\n",
            "content          0\n",
            "clean_content    0\n",
            "dtype: int64\n",
            "\n",
            "Dataset shape after dropping missing values: (40000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_content'] = df['content'].apply(lambda x: clean_text(x))\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "X = df['clean_content']\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "X_tfidf_dense = X_tfidf.toarray()\n",
        "print(\"Shape of TF-IDF matrix:\", X_tfidf_dense.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucF5Ml0a8xGW",
        "outputId": "8e46eed5-7a43-43f1-8ea1-eb4dce481d45"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF matrix: (40000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip().lower()\n",
        "\n",
        "df['clean_content'] = df['content'].apply(clean_text)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X = df['clean_content']\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "X_tfidf_dense = X_tfidf.toarray()\n"
      ],
      "metadata": {
        "id": "ZvcWUcNG-pHk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_dense, df['sentiment'], test_size=0.2, random_state=42)\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "print(\"Naive Bayes Classifier Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "cv_scores = cross_val_score(nb_classifier, X_tfidf_dense, df['sentiment'], cv=5)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzjFW8NNAgh9",
        "outputId": "f1c507ab-f2e2-423f-be63-6158629e0072"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier Performance:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.00      0.00      0.00        19\n",
            "     boredom       0.00      0.00      0.00        31\n",
            "       empty       0.00      0.00      0.00       162\n",
            "  enthusiasm       0.00      0.00      0.00       163\n",
            "         fun       0.00      0.00      0.00       338\n",
            "   happiness       0.35      0.30      0.32      1028\n",
            "        hate       0.43      0.01      0.02       268\n",
            "        love       0.51      0.30      0.38       762\n",
            "     neutral       0.30      0.56      0.39      1740\n",
            "      relief       0.00      0.00      0.00       352\n",
            "     sadness       0.39      0.14      0.21      1046\n",
            "    surprise       1.00      0.00      0.01       425\n",
            "       worry       0.30      0.55      0.39      1666\n",
            "\n",
            "    accuracy                           0.32      8000\n",
            "   macro avg       0.25      0.14      0.13      8000\n",
            "weighted avg       0.34      0.32      0.27      8000\n",
            "\n",
            "Accuracy: 0.323\n",
            "Cross-validation scores: [0.2785   0.303625 0.34525  0.348125 0.302875]\n",
            "Mean CV accuracy: 0.31567500000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(df['sentiment'])\n",
        "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_tfidf_dense, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define deep learning model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train_dl.shape[1], activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train_dl, y_train_dl, epochs=10, batch_size=32, validation_data=(X_test_dl, y_test_dl))\n",
        "loss, accuracy = model.evaluate(X_test_dl, y_test_dl)\n",
        "print(\"Deep Learning Model Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkIsH0DkBWi3",
        "outputId": "b1a0d9b3-765a-49b1-d8b6-69a339655011"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 2.0897 - accuracy: 0.2680 - val_loss: 1.9351 - val_accuracy: 0.3383\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.8802 - accuracy: 0.3626 - val_loss: 1.9117 - val_accuracy: 0.3470\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.7661 - accuracy: 0.4067 - val_loss: 1.9297 - val_accuracy: 0.3455\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.6717 - accuracy: 0.4435 - val_loss: 1.9643 - val_accuracy: 0.3376\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 1.5803 - accuracy: 0.4760 - val_loss: 2.0076 - val_accuracy: 0.3385\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 1.4864 - accuracy: 0.5090 - val_loss: 2.0599 - val_accuracy: 0.3301\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 1.3902 - accuracy: 0.5404 - val_loss: 2.1379 - val_accuracy: 0.3246\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.2991 - accuracy: 0.5698 - val_loss: 2.2499 - val_accuracy: 0.3215\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.2246 - accuracy: 0.6012 - val_loss: 2.3378 - val_accuracy: 0.3251\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.1362 - accuracy: 0.6254 - val_loss: 2.4373 - val_accuracy: 0.3180\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 2.4373 - accuracy: 0.3180\n",
            "Deep Learning Model Accuracy: 0.3179999887943268\n"
          ]
        }
      ]
    }
  ]
}